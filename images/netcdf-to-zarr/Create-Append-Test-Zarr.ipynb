{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zarr store directory: /fsx/eodc/eodc/mursst_zarr/5x1799x3600_encoded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numcodecs\n",
    "from dask.distributed import Client, progress, LocalCluster\n",
    "import zarr\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def generate_file_list(start_doy, end_doy):   \n",
    "    \"\"\"\n",
    "    Given a start day and end end day, generate a list of file locations.\n",
    "    Assumes a 'prefix' and 'year' variables have already been defined.\n",
    "    'Prefix' should be a local directory or http url and path.\n",
    "    'Year' should be a 4 digit year.\n",
    "    \"\"\"\n",
    "    days_of_year = list(range(start_doy, end_doy))\n",
    "    fileObjs = []\n",
    "    for doy in days_of_year:\n",
    "        if doy < 10:\n",
    "            doy = f\"00{doy}\"\n",
    "        elif doy >= 10 and doy < 100:\n",
    "            doy = f\"0{doy}\"            \n",
    "        file = glob.glob(f\"{prefix}/{doy}/*.nc\")[0]\n",
    "        fileObjs.append(file)\n",
    "    return fileObjs\n",
    "\n",
    "# Invariants - but should be made configurable\n",
    "year = 2002\n",
    "prefix = f\"/fsx/eodc/eodc/mursst_netcdf/{year}\"\n",
    "chunks = {'time': 5, 'lat': 1799, 'lon': 3600}\n",
    "path = 'x'.join(map(str, chunks.values()))\n",
    "store_dir = f\"/fsx/eodc/eodc/mursst_zarr/{path}_encoded\"\n",
    "numcodecs.blosc.use_threads = False\n",
    "print(f\"zarr store directory: {store_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask client <Client: 'tcp://127.0.0.1:34197' processes=4 threads=32, memory=125.83 GB>\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCluster(n_workers=4)\n",
    "client = Client(cluster)\n",
    "print(f\"Dask client {client}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start doy: 362, file: 20021228090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n",
      "end doy: 366, file: 20021231090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n",
      "Done with this batch\n",
      "\n",
      "CPU times: user 4.5 s, sys: 467 ms, total: 4.96 s\n",
      "Wall time: 50.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop and append\n",
    "start_doy = 362\n",
    "end_doy = start_doy\n",
    "number_batches_to_append = 1\n",
    "batch_size = 4\n",
    "final_end_doy = start_doy + (number_batches_to_append * batch_size)\n",
    "\n",
    "while start_doy < final_end_doy:\n",
    "    end_doy = start_doy + batch_size\n",
    "    end_doy = min(366, end_doy)\n",
    "    fileObjs = generate_file_list(start_doy, end_doy)\n",
    "    first_file = fileObjs[0].split('/')[-1]\n",
    "    last_file = fileObjs[-1].split('/')[-1]\n",
    "    print(f\"start doy: {start_doy}, file: {first_file}\")\n",
    "    print(f\"end doy: {end_doy}, file: {last_file}\")\n",
    "    args = {'consolidated': True}\n",
    "    # Either append or initiate store\n",
    "    if start_doy == 152 and year == 2002:\n",
    "        ds = xr.open_mfdataset(fileObjs, parallel=True, combine='by_coords', mask_and_scale=False)\n",
    "        ds = ds.chunk(chunks)       \n",
    "        args['mode'] = 'w'\n",
    "    else:\n",
    "        # Check here that the next day we will append is the next day in the year\n",
    "        current_ds = xr.open_zarr(store_dir, consolidated=True)\n",
    "        next_day = current_ds.time[-1].values + np.timedelta64(1,'D')\n",
    "        next_day_str = str(next_day)[0:10].replace('-', '') \n",
    "        if not (first_file[0:8] == next_day_str):\n",
    "            raise Exception(\"starting file is not the next day of the year\")\n",
    "            break\n",
    "        ds = xr.open_mfdataset(fileObjs, parallel=True, combine='by_coords')\n",
    "        ds = ds.chunk(chunks)        \n",
    "        args['mode'] = 'a'\n",
    "        args['append_dim'] = 'time'\n",
    "    ds.to_zarr(store_dir, **args)\n",
    "    start_doy = end_doy\n",
    "    print(f\"Done with this batch\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:           (lat: 17999, lon: 36000, time: 214)\n",
       "Coordinates:\n",
       "  * lat               (lat) float32 -89.99 -89.98 -89.97 ... 89.97 89.98 89.99\n",
       "  * lon               (lon) float32 -179.99 -179.98 -179.97 ... 179.99 180.0\n",
       "  * time              (time) datetime64[ns] 2002-06-01T09:00:00 ... 2002-12-31T09:00:00\n",
       "Data variables:\n",
       "    analysed_sst      (time, lat, lon) int16 dask.array&lt;chunksize=(5, 1799, 3600), meta=np.ndarray&gt;\n",
       "    analysis_error    (time, lat, lon) int16 dask.array&lt;chunksize=(5, 1799, 3600), meta=np.ndarray&gt;\n",
       "    mask              (time, lat, lon) int8 dask.array&lt;chunksize=(5, 1799, 3600), meta=np.ndarray&gt;\n",
       "    sea_ice_fraction  (time, lat, lon) int8 dask.array&lt;chunksize=(5, 1799, 3600), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    Conventions:                CF-1.5\n",
       "    Metadata_Conventions:       Unidata Observation Dataset v1.0\n",
       "    acknowledgment:             Please acknowledge the use of these data with...\n",
       "    cdm_data_type:              grid\n",
       "    comment:                    MUR = &quot;Multi-scale Ultra-high Reolution&quot;\n",
       "    creator_email:              ghrsst@podaac.jpl.nasa.gov\n",
       "    creator_name:               JPL MUR SST project\n",
       "    creator_url:                http://mur.jpl.nasa.gov\n",
       "    date_created:               20150818T191705Z\n",
       "    easternmost_longitude:      180.0\n",
       "    file_quality_level:         1\n",
       "    gds_version_id:             2.0\n",
       "    geospatial_lat_resolution:  0.01 degrees\n",
       "    geospatial_lat_units:       degrees north\n",
       "    geospatial_lon_resolution:  0.01 degrees\n",
       "    geospatial_lon_units:       degrees east\n",
       "    history:                    created at nominal 4-day latency; replaced nr...\n",
       "    id:                         MUR-JPL-L4-GLOB-v04.1\n",
       "    institution:                Jet Propulsion Laboratory\n",
       "    keywords:                   Oceans &gt; Ocean Temperature &gt; Sea Surface Temp...\n",
       "    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n",
       "    license:                    These data are available free of charge under...\n",
       "    metadata_link:              http://podaac.jpl.nasa.gov/ws/metadata/datase...\n",
       "    naming_authority:           org.ghrsst\n",
       "    netcdf_version_id:          4.1\n",
       "    northernmost_latitude:      90.0\n",
       "    platform:                   Aqua, DMSP, NOAA-POES, Suomi-NPP, Terra\n",
       "    processing_level:           L4\n",
       "    product_version:            04.1\n",
       "    project:                    NASA Making Earth Science Data Records for Us...\n",
       "    publisher_email:            ghrsst-po@nceo.ac.uk\n",
       "    publisher_name:             GHRSST Project Office\n",
       "    publisher_url:              http://www.ghrsst.org\n",
       "    references:                 http://podaac.jpl.nasa.gov/Multi-scale_Ultra-...\n",
       "    sensor:                     AMSR-E, AVHRR, MODIS, SSM/I, VIIRS, in-situ\n",
       "    source:                     AMSRE-REMSS, AVHRR_Pathfinder-PFV5.2-NODC_day...\n",
       "    southernmost_latitude:      -90.0\n",
       "    spatial_resolution:         0.01 degrees\n",
       "    standard_name_vocabulary:   NetCDF Climate and Forecast (CF) Metadata Con...\n",
       "    start_time:                 20021228T090000Z\n",
       "    stop_time:                  20021228T090000Z\n",
       "    summary:                    A merged, multi-sensor L4 Foundation SST anal...\n",
       "    time_coverage_end:          20021228T210000Z\n",
       "    time_coverage_start:        20021227T210000Z\n",
       "    title:                      Daily MUR SST, Final product\n",
       "    uuid:                       27665bc0-d5fc-11e1-9b23-0800200c9a66\n",
       "    westernmost_longitude:      -180.0</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:           (lat: 17999, lon: 36000, time: 214)\n",
       "Coordinates:\n",
       "  * lat               (lat) float32 -89.99 -89.98 -89.97 ... 89.97 89.98 89.99\n",
       "  * lon               (lon) float32 -179.99 -179.98 -179.97 ... 179.99 180.0\n",
       "  * time              (time) datetime64[ns] 2002-06-01T09:00:00 ... 2002-12-31T09:00:00\n",
       "Data variables:\n",
       "    analysed_sst      (time, lat, lon) int16 dask.array<chunksize=(5, 1799, 3600), meta=np.ndarray>\n",
       "    analysis_error    (time, lat, lon) int16 dask.array<chunksize=(5, 1799, 3600), meta=np.ndarray>\n",
       "    mask              (time, lat, lon) int8 dask.array<chunksize=(5, 1799, 3600), meta=np.ndarray>\n",
       "    sea_ice_fraction  (time, lat, lon) int8 dask.array<chunksize=(5, 1799, 3600), meta=np.ndarray>\n",
       "Attributes:\n",
       "    Conventions:                CF-1.5\n",
       "    Metadata_Conventions:       Unidata Observation Dataset v1.0\n",
       "    acknowledgment:             Please acknowledge the use of these data with...\n",
       "    cdm_data_type:              grid\n",
       "    comment:                    MUR = \"Multi-scale Ultra-high Reolution\"\n",
       "    creator_email:              ghrsst@podaac.jpl.nasa.gov\n",
       "    creator_name:               JPL MUR SST project\n",
       "    creator_url:                http://mur.jpl.nasa.gov\n",
       "    date_created:               20150818T191705Z\n",
       "    easternmost_longitude:      180.0\n",
       "    file_quality_level:         1\n",
       "    gds_version_id:             2.0\n",
       "    geospatial_lat_resolution:  0.01 degrees\n",
       "    geospatial_lat_units:       degrees north\n",
       "    geospatial_lon_resolution:  0.01 degrees\n",
       "    geospatial_lon_units:       degrees east\n",
       "    history:                    created at nominal 4-day latency; replaced nr...\n",
       "    id:                         MUR-JPL-L4-GLOB-v04.1\n",
       "    institution:                Jet Propulsion Laboratory\n",
       "    keywords:                   Oceans > Ocean Temperature > Sea Surface Temp...\n",
       "    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n",
       "    license:                    These data are available free of charge under...\n",
       "    metadata_link:              http://podaac.jpl.nasa.gov/ws/metadata/datase...\n",
       "    naming_authority:           org.ghrsst\n",
       "    netcdf_version_id:          4.1\n",
       "    northernmost_latitude:      90.0\n",
       "    platform:                   Aqua, DMSP, NOAA-POES, Suomi-NPP, Terra\n",
       "    processing_level:           L4\n",
       "    product_version:            04.1\n",
       "    project:                    NASA Making Earth Science Data Records for Us...\n",
       "    publisher_email:            ghrsst-po@nceo.ac.uk\n",
       "    publisher_name:             GHRSST Project Office\n",
       "    publisher_url:              http://www.ghrsst.org\n",
       "    references:                 http://podaac.jpl.nasa.gov/Multi-scale_Ultra-...\n",
       "    sensor:                     AMSR-E, AVHRR, MODIS, SSM/I, VIIRS, in-situ\n",
       "    source:                     AMSRE-REMSS, AVHRR_Pathfinder-PFV5.2-NODC_day...\n",
       "    southernmost_latitude:      -90.0\n",
       "    spatial_resolution:         0.01 degrees\n",
       "    standard_name_vocabulary:   NetCDF Climate and Forecast (CF) Metadata Con...\n",
       "    start_time:                 20021228T090000Z\n",
       "    stop_time:                  20021228T090000Z\n",
       "    summary:                    A merged, multi-sensor L4 Foundation SST anal...\n",
       "    time_coverage_end:          20021228T210000Z\n",
       "    time_coverage_start:        20021227T210000Z\n",
       "    title:                      Daily MUR SST, Final product\n",
       "    uuid:                       27665bc0-d5fc-11e1-9b23-0800200c9a66\n",
       "    westernmost_longitude:      -180.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_zarr = xr.open_zarr(store_dir, consolidated=True, mask_and_scale=False)\n",
    "ds_zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the output\n",
    "\n",
    "Assuming we are using 1x1799x3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start doy: 152, file: 20020601090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n",
      "end doy: 162, file: 20020610090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n",
      "CPU times: user 97.2 ms, sys: 20.2 ms, total: 117 ms\n",
      "Wall time: 839 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "time_slice = slice(datetime.strptime(f\"{year}-06-04\", '%Y-%m-%d'), datetime.strptime(f\"{year}-06-08\", '%Y-%m-%d'))\n",
    "\n",
    "start_doy = 152\n",
    "end_doy = 162\n",
    "\n",
    "fileObjs = generate_file_list(start_doy, end_doy)\n",
    "print(f\"start doy: {start_doy}, file: {fileObjs[0].split('/')[-1]}\")\n",
    "print(f\"end doy: {end_doy}, file: {fileObjs[-1].split('/')[-1]}\")          \n",
    "ds_netcdf = xr.open_mfdataset(fileObjs, chunks=chunks, parallel=True, combine='by_coords', mask_and_scale=False)\n",
    "assert(ds_netcdf.dims == ds_zarr.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_netcdf_masked = xr.open_mfdataset(fileObjs, chunks=chunks, parallel=True, combine='by_coords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294.50433\n",
      "CPU times: user 1.56 s, sys: 93.1 ms, total: 1.65 s\n",
      "Wall time: 13.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(286.7686, dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(ds_netcdf_masked.analysed_sst[5:8,:,:].sel(lat=slice(0,50),lon=slice(-170,-110)).mean().values)\n",
    "ds_netcdf_masked.analysed_sst.sel(time=time_slice).mean().values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294.5043725203148\n",
      "CPU times: user 2.15 s, sys: 211 ms, total: 2.36 s\n",
      "Wall time: 12 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "286.7688028626251"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(ds_netcdf.where(ds_netcdf.analysed_sst != -32768).analysed_sst[5:8,:,:].sel(lat=slice(0,50),lon=slice(-170,-110)).mean().values * 0.001 + 298.15)\n",
    "ds_netcdf.where(ds_netcdf.analysed_sst != -32768).analysed_sst.sel(time=time_slice).mean().values * 0.001 + 298.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294.5043725203148\n",
      "CPU times: user 2.89 s, sys: 222 ms, total: 3.11 s\n",
      "Wall time: 12.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "286.7688028626251"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(ds_zarr.where(ds_zarr.analysed_sst != -32768).analysed_sst[5:8,:,:].sel(lat=slice(0,50),lon=slice(-170,-110)).mean().values * 0.001 + 298.15)\n",
    "ds_zarr.where(ds_netcdf.analysed_sst != -32768).analysed_sst.sel(time=time_slice).mean().values * 0.001 + 298.15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:netcdf_to_zarr] *",
   "language": "python",
   "name": "conda-env-netcdf_to_zarr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
