{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numcodecs\n",
    "from dask.distributed import Client, progress, LocalCluster\n",
    "import zarr\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import time\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask client <Client: 'tcp://127.0.0.1:33511' processes=4 threads=64, memory=535.16 GB>\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCluster(n_workers=4)\n",
    "client = Client(cluster)\n",
    "print(f\"Dask client {client}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_list(start_doy, end_doy, year):   \n",
    "    \"\"\"\n",
    "    Given a start day and end end day, generate a list of file locations.\n",
    "    Assumes a 'prefix' and 'year' variables have already been defined.\n",
    "    'Prefix' should be a local directory or http url and path.\n",
    "    'Year' should be a 4 digit year.\n",
    "    \"\"\"\n",
    "    days_of_year = list(range(start_doy, end_doy))\n",
    "    fileObjs = []\n",
    "    for doy in days_of_year:\n",
    "        if doy < 10:\n",
    "            doy = f\"00{doy}\"\n",
    "        elif doy >= 10 and doy < 100:\n",
    "            doy = f\"0{doy}\"            \n",
    "        file = glob.glob(f\"{netcdf_prefix}/{year}/{doy}/*.nc\")[0]\n",
    "        fileObjs.append(file)\n",
    "    return fileObjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zarr store directory: /s3fsx/eodc/mursst_zarr/5x1799x3600\n"
     ]
    }
   ],
   "source": [
    "# Invariants - but should be made configurable\n",
    "netcdf_prefix = f\"/s3fsx/eodc/mursst_netcdf\"\n",
    "chunks = {'time': 5, 'lat': 1799, 'lon': 3600}\n",
    "path = 'x'.join(map(str, chunks.values()))\n",
    "# CLI Argument - zarr directory\n",
    "store_dir = f\"/s3fsx/eodc/mursst_zarr/5x1799x3600\"\n",
    "numcodecs.blosc.use_threads = False\n",
    "print(f\"zarr store directory: {store_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 33% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 33% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.47 s, sys: 140 ms, total: 3.61 s\n",
      "Wall time: 6.25 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:           (lat: 17999, lon: 36000, time: 5328)\n",
       "Coordinates:\n",
       "  * lat               (lat) float32 -89.99 -89.98 -89.97 ... 89.97 89.98 89.99\n",
       "  * lon               (lon) float32 -179.99 -179.98 -179.97 ... 179.99 180.0\n",
       "  * time              (time) datetime64[ns] 2002-06-01T09:00:00 ... 2016-12-31T09:00:00\n",
       "Data variables:\n",
       "    analysed_sst      (time, lat, lon) int16 dask.array&lt;chunksize=(5, 1799, 3600), meta=np.ndarray&gt;\n",
       "    analysis_error    (time, lat, lon) int16 dask.array&lt;chunksize=(5, 1799, 3600), meta=np.ndarray&gt;\n",
       "    mask              (time, lat, lon) int8 dask.array&lt;chunksize=(5, 1799, 3600), meta=np.ndarray&gt;\n",
       "    sea_ice_fraction  (time, lat, lon) int8 dask.array&lt;chunksize=(5, 1799, 3600), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    Conventions:                CF-1.5\n",
       "    Metadata_Conventions:       Unidata Observation Dataset v1.0\n",
       "    acknowledgment:             Please acknowledge the use of these data with...\n",
       "    cdm_data_type:              grid\n",
       "    comment:                    MUR = &quot;Multi-scale Ultra-high Reolution&quot;\n",
       "    creator_email:              ghrsst@podaac.jpl.nasa.gov\n",
       "    creator_name:               JPL MUR SST project\n",
       "    creator_url:                http://mur.jpl.nasa.gov\n",
       "    date_created:               20170104T014705Z\n",
       "    easternmost_longitude:      180.0\n",
       "    file_quality_level:         1\n",
       "    gds_version_id:             2.0\n",
       "    geospatial_lat_resolution:  0.01 degrees\n",
       "    geospatial_lat_units:       degrees north\n",
       "    geospatial_lon_resolution:  0.01 degrees\n",
       "    geospatial_lon_units:       degrees east\n",
       "    history:                    created at nominal 4-day latency; replaced nr...\n",
       "    id:                         MUR-JPL-L4-GLOB-v04.1\n",
       "    institution:                Jet Propulsion Laboratory\n",
       "    keywords:                   Oceans &gt; Ocean Temperature &gt; Sea Surface Temp...\n",
       "    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n",
       "    license:                    These data are available free of charge under...\n",
       "    metadata_link:              http://podaac.jpl.nasa.gov/ws/metadata/datase...\n",
       "    naming_authority:           org.ghrsst\n",
       "    netcdf_version_id:          4.1\n",
       "    northernmost_latitude:      90.0\n",
       "    platform:                   Aqua, DMSP, NOAA-POES, Suomi-NPP, Terra\n",
       "    processing_level:           L4\n",
       "    product_version:            04.1\n",
       "    project:                    NASA Making Earth Science Data Records for Us...\n",
       "    publisher_email:            ghrsst-po@nceo.ac.uk\n",
       "    publisher_name:             GHRSST Project Office\n",
       "    publisher_url:              http://www.ghrsst.org\n",
       "    references:                 http://podaac.jpl.nasa.gov/Multi-scale_Ultra-...\n",
       "    sensor:                     AMSR-E, AVHRR, MODIS, SSM/I, VIIRS, in-situ\n",
       "    source:                     AVHRR19_G-NAVO, AVHRR_METOP_A-EUMETSAT, MODIS...\n",
       "    southernmost_latitude:      -90.0\n",
       "    spatial_resolution:         0.01 degrees\n",
       "    standard_name_vocabulary:   NetCDF Climate and Forecast (CF) Metadata Con...\n",
       "    start_time:                 20161231T090000Z\n",
       "    stop_time:                  20161231T090000Z\n",
       "    summary:                    A merged, multi-sensor L4 Foundation SST anal...\n",
       "    time_coverage_end:          20161231T210000Z\n",
       "    time_coverage_start:        20161230T210000Z\n",
       "    title:                      Daily MUR SST, Final product\n",
       "    uuid:                       27665bc0-d5fc-11e1-9b23-0800200c9a66\n",
       "    westernmost_longitude:      -180.0</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:           (lat: 17999, lon: 36000, time: 5328)\n",
       "Coordinates:\n",
       "  * lat               (lat) float32 -89.99 -89.98 -89.97 ... 89.97 89.98 89.99\n",
       "  * lon               (lon) float32 -179.99 -179.98 -179.97 ... 179.99 180.0\n",
       "  * time              (time) datetime64[ns] 2002-06-01T09:00:00 ... 2016-12-31T09:00:00\n",
       "Data variables:\n",
       "    analysed_sst      (time, lat, lon) int16 dask.array<chunksize=(5, 1799, 3600), meta=np.ndarray>\n",
       "    analysis_error    (time, lat, lon) int16 dask.array<chunksize=(5, 1799, 3600), meta=np.ndarray>\n",
       "    mask              (time, lat, lon) int8 dask.array<chunksize=(5, 1799, 3600), meta=np.ndarray>\n",
       "    sea_ice_fraction  (time, lat, lon) int8 dask.array<chunksize=(5, 1799, 3600), meta=np.ndarray>\n",
       "Attributes:\n",
       "    Conventions:                CF-1.5\n",
       "    Metadata_Conventions:       Unidata Observation Dataset v1.0\n",
       "    acknowledgment:             Please acknowledge the use of these data with...\n",
       "    cdm_data_type:              grid\n",
       "    comment:                    MUR = \"Multi-scale Ultra-high Reolution\"\n",
       "    creator_email:              ghrsst@podaac.jpl.nasa.gov\n",
       "    creator_name:               JPL MUR SST project\n",
       "    creator_url:                http://mur.jpl.nasa.gov\n",
       "    date_created:               20170104T014705Z\n",
       "    easternmost_longitude:      180.0\n",
       "    file_quality_level:         1\n",
       "    gds_version_id:             2.0\n",
       "    geospatial_lat_resolution:  0.01 degrees\n",
       "    geospatial_lat_units:       degrees north\n",
       "    geospatial_lon_resolution:  0.01 degrees\n",
       "    geospatial_lon_units:       degrees east\n",
       "    history:                    created at nominal 4-day latency; replaced nr...\n",
       "    id:                         MUR-JPL-L4-GLOB-v04.1\n",
       "    institution:                Jet Propulsion Laboratory\n",
       "    keywords:                   Oceans > Ocean Temperature > Sea Surface Temp...\n",
       "    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n",
       "    license:                    These data are available free of charge under...\n",
       "    metadata_link:              http://podaac.jpl.nasa.gov/ws/metadata/datase...\n",
       "    naming_authority:           org.ghrsst\n",
       "    netcdf_version_id:          4.1\n",
       "    northernmost_latitude:      90.0\n",
       "    platform:                   Aqua, DMSP, NOAA-POES, Suomi-NPP, Terra\n",
       "    processing_level:           L4\n",
       "    product_version:            04.1\n",
       "    project:                    NASA Making Earth Science Data Records for Us...\n",
       "    publisher_email:            ghrsst-po@nceo.ac.uk\n",
       "    publisher_name:             GHRSST Project Office\n",
       "    publisher_url:              http://www.ghrsst.org\n",
       "    references:                 http://podaac.jpl.nasa.gov/Multi-scale_Ultra-...\n",
       "    sensor:                     AMSR-E, AVHRR, MODIS, SSM/I, VIIRS, in-situ\n",
       "    source:                     AVHRR19_G-NAVO, AVHRR_METOP_A-EUMETSAT, MODIS...\n",
       "    southernmost_latitude:      -90.0\n",
       "    spatial_resolution:         0.01 degrees\n",
       "    standard_name_vocabulary:   NetCDF Climate and Forecast (CF) Metadata Con...\n",
       "    start_time:                 20161231T090000Z\n",
       "    stop_time:                  20161231T090000Z\n",
       "    summary:                    A merged, multi-sensor L4 Foundation SST anal...\n",
       "    time_coverage_end:          20161231T210000Z\n",
       "    time_coverage_start:        20161230T210000Z\n",
       "    title:                      Daily MUR SST, Final product\n",
       "    uuid:                       27665bc0-d5fc-11e1-9b23-0800200c9a66\n",
       "    westernmost_longitude:      -180.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ds_zarr = xr.open_zarr(store_dir, consolidated=True, mask_and_scale=False)\n",
    "ds_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start doy: 366, starting file: 20161231090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n",
      "end doy: 367, ending file: 20161231090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 33% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 33% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 35% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with this batch\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop and append\n",
    "# Command Line Argument - year, start_day, number_batches_to_append, batch_size\n",
    "year = 2016\n",
    "start_doy = 366\n",
    "end_doy = start_doy\n",
    "number_batches_to_append = 1\n",
    "batch_size = 5\n",
    "final_end_doy = start_doy + (number_batches_to_append * batch_size)\n",
    "\n",
    "while start_doy < final_end_doy:\n",
    "    end_doy = start_doy + batch_size\n",
    "    end_doy = min(367, end_doy)\n",
    "    fileObjs = generate_file_list(start_doy, end_doy, year)\n",
    "    first_file = fileObjs[0].split('/')[-1]\n",
    "    last_file = fileObjs[-1].split('/')[-1]\n",
    "    print(f\"start doy: {start_doy}, starting file: {first_file}\")\n",
    "    print(f\"end doy: {end_doy}, ending file: {last_file}\")\n",
    "    args = {'consolidated': True}\n",
    "    # Either append or initiate store\n",
    "    if start_doy == 152 and year == 2002:\n",
    "        ds = xr.open_mfdataset(fileObjs, parallel=True, combine='by_coords', mask_and_scale=False)\n",
    "        ds = ds.chunk(chunks)       \n",
    "        args['mode'] = 'w'\n",
    "    else:\n",
    "        # Check here that the next day we will append is the next day in the year\n",
    "        current_ds = xr.open_zarr(store_dir, consolidated=True)\n",
    "        next_day = current_ds.time[-1].values + np.timedelta64(1, 'D')\n",
    "        next_day_str = str(next_day)[0:10].replace('-', '') \n",
    "        if not (first_file[0:8] == next_day_str):\n",
    "            raise Exception(\"starting file is not the next day of the year\")\n",
    "            break\n",
    "        drop_vars = ['dt_1km_data', 'sst_anomaly']\n",
    "        ds = xr.open_mfdataset(fileObjs, parallel=True, combine='by_coords', drop_variables=drop_vars)\n",
    "        ds = ds.chunk(chunks)        \n",
    "        args['mode'] = 'a'\n",
    "        args['append_dim'] = 'time'\n",
    "    ds.to_zarr(store_dir, **args)\n",
    "    start_doy = end_doy\n",
    "    print(f\"Done with this batch\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = slice(datetime.strptime(f\"2016-12-21\", '%Y-%m-%d'), datetime.strptime(f\"2016-12-31\", '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting file: 20160101090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n",
      "ending file: 20161231090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n",
      "CPU times: user 1.89 s, sys: 760 ms, total: 2.65 s\n",
      "Wall time: 8.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:           (lat: 17999, lon: 36000, time: 366)\n",
       "Coordinates:\n",
       "  * lat               (lat) float32 -89.99 -89.98 -89.97 ... 89.97 89.98 89.99\n",
       "  * lon               (lon) float32 -179.99 -179.98 -179.97 ... 179.99 180.0\n",
       "  * time              (time) datetime64[ns] 2016-01-01T09:00:00 ... 2016-12-31T09:00:00\n",
       "Data variables:\n",
       "    analysed_sst      (time, lat, lon) int16 dask.array&lt;chunksize=(1, 17999, 36000), meta=np.ndarray&gt;\n",
       "    analysis_error    (time, lat, lon) int16 dask.array&lt;chunksize=(1, 17999, 36000), meta=np.ndarray&gt;\n",
       "    mask              (time, lat, lon) int8 dask.array&lt;chunksize=(1, 17999, 36000), meta=np.ndarray&gt;\n",
       "    sea_ice_fraction  (time, lat, lon) int8 dask.array&lt;chunksize=(1, 17999, 36000), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    Conventions:                CF-1.5\n",
       "    title:                      Daily MUR SST, Final product\n",
       "    summary:                    A merged, multi-sensor L4 Foundation SST anal...\n",
       "    references:                 http://podaac.jpl.nasa.gov/Multi-scale_Ultra-...\n",
       "    institution:                Jet Propulsion Laboratory\n",
       "    history:                    created at nominal 4-day latency; replaced nr...\n",
       "    comment:                    MUR = &quot;Multi-scale Ultra-high Reolution&quot;\n",
       "    license:                    These data are available free of charge under...\n",
       "    id:                         MUR-JPL-L4-GLOB-v04.1\n",
       "    naming_authority:           org.ghrsst\n",
       "    product_version:            04.1\n",
       "    uuid:                       27665bc0-d5fc-11e1-9b23-0800200c9a66\n",
       "    gds_version_id:             2.0\n",
       "    netcdf_version_id:          4.1\n",
       "    date_created:               20180727T190247Z\n",
       "    start_time:                 20160101T090000Z\n",
       "    stop_time:                  20160101T090000Z\n",
       "    time_coverage_start:        20151231T210000Z\n",
       "    time_coverage_end:          20160101T210000Z\n",
       "    file_quality_level:         1\n",
       "    source:                     MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRR1...\n",
       "    platform:                   Terra, Aqua, GCOM-W, NOAA-19, MetOp-A, Buoys/...\n",
       "    sensor:                     MODIS, AMSR2, AVHRR, in-situ\n",
       "    Metadata_Conventions:       Unidata Observation Dataset v1.0\n",
       "    metadata_link:              http://podaac.jpl.nasa.gov/ws/metadata/datase...\n",
       "    keywords:                   Oceans &gt; Ocean Temperature &gt; Sea Surface Temp...\n",
       "    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n",
       "    standard_name_vocabulary:   NetCDF Climate and Forecast (CF) Metadata Con...\n",
       "    southernmost_latitude:      -90.0\n",
       "    northernmost_latitude:      90.0\n",
       "    westernmost_longitude:      -180.0\n",
       "    easternmost_longitude:      180.0\n",
       "    spatial_resolution:         0.01 degrees\n",
       "    geospatial_lat_units:       degrees north\n",
       "    geospatial_lat_resolution:  0.01 degrees\n",
       "    geospatial_lon_units:       degrees east\n",
       "    geospatial_lon_resolution:  0.01 degrees\n",
       "    acknowledgment:             Please acknowledge the use of these data with...\n",
       "    creator_name:               JPL MUR SST project\n",
       "    creator_email:              ghrsst@podaac.jpl.nasa.gov\n",
       "    creator_url:                http://mur.jpl.nasa.gov\n",
       "    project:                    NASA Making Earth Science Data Records for Us...\n",
       "    publisher_name:             GHRSST Project Office\n",
       "    publisher_url:              http://www.ghrsst.org\n",
       "    publisher_email:            ghrsst-po@nceo.ac.uk\n",
       "    processing_level:           L4\n",
       "    cdm_data_type:              grid</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:           (lat: 17999, lon: 36000, time: 366)\n",
       "Coordinates:\n",
       "  * lat               (lat) float32 -89.99 -89.98 -89.97 ... 89.97 89.98 89.99\n",
       "  * lon               (lon) float32 -179.99 -179.98 -179.97 ... 179.99 180.0\n",
       "  * time              (time) datetime64[ns] 2016-01-01T09:00:00 ... 2016-12-31T09:00:00\n",
       "Data variables:\n",
       "    analysed_sst      (time, lat, lon) int16 dask.array<chunksize=(1, 17999, 36000), meta=np.ndarray>\n",
       "    analysis_error    (time, lat, lon) int16 dask.array<chunksize=(1, 17999, 36000), meta=np.ndarray>\n",
       "    mask              (time, lat, lon) int8 dask.array<chunksize=(1, 17999, 36000), meta=np.ndarray>\n",
       "    sea_ice_fraction  (time, lat, lon) int8 dask.array<chunksize=(1, 17999, 36000), meta=np.ndarray>\n",
       "Attributes:\n",
       "    Conventions:                CF-1.5\n",
       "    title:                      Daily MUR SST, Final product\n",
       "    summary:                    A merged, multi-sensor L4 Foundation SST anal...\n",
       "    references:                 http://podaac.jpl.nasa.gov/Multi-scale_Ultra-...\n",
       "    institution:                Jet Propulsion Laboratory\n",
       "    history:                    created at nominal 4-day latency; replaced nr...\n",
       "    comment:                    MUR = \"Multi-scale Ultra-high Reolution\"\n",
       "    license:                    These data are available free of charge under...\n",
       "    id:                         MUR-JPL-L4-GLOB-v04.1\n",
       "    naming_authority:           org.ghrsst\n",
       "    product_version:            04.1\n",
       "    uuid:                       27665bc0-d5fc-11e1-9b23-0800200c9a66\n",
       "    gds_version_id:             2.0\n",
       "    netcdf_version_id:          4.1\n",
       "    date_created:               20180727T190247Z\n",
       "    start_time:                 20160101T090000Z\n",
       "    stop_time:                  20160101T090000Z\n",
       "    time_coverage_start:        20151231T210000Z\n",
       "    time_coverage_end:          20160101T210000Z\n",
       "    file_quality_level:         1\n",
       "    source:                     MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRR1...\n",
       "    platform:                   Terra, Aqua, GCOM-W, NOAA-19, MetOp-A, Buoys/...\n",
       "    sensor:                     MODIS, AMSR2, AVHRR, in-situ\n",
       "    Metadata_Conventions:       Unidata Observation Dataset v1.0\n",
       "    metadata_link:              http://podaac.jpl.nasa.gov/ws/metadata/datase...\n",
       "    keywords:                   Oceans > Ocean Temperature > Sea Surface Temp...\n",
       "    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n",
       "    standard_name_vocabulary:   NetCDF Climate and Forecast (CF) Metadata Con...\n",
       "    southernmost_latitude:      -90.0\n",
       "    northernmost_latitude:      90.0\n",
       "    westernmost_longitude:      -180.0\n",
       "    easternmost_longitude:      180.0\n",
       "    spatial_resolution:         0.01 degrees\n",
       "    geospatial_lat_units:       degrees north\n",
       "    geospatial_lat_resolution:  0.01 degrees\n",
       "    geospatial_lon_units:       degrees east\n",
       "    geospatial_lon_resolution:  0.01 degrees\n",
       "    acknowledgment:             Please acknowledge the use of these data with...\n",
       "    creator_name:               JPL MUR SST project\n",
       "    creator_email:              ghrsst@podaac.jpl.nasa.gov\n",
       "    creator_url:                http://mur.jpl.nasa.gov\n",
       "    project:                    NASA Making Earth Science Data Records for Us...\n",
       "    publisher_name:             GHRSST Project Office\n",
       "    publisher_url:              http://www.ghrsst.org\n",
       "    publisher_email:            ghrsst-po@nceo.ac.uk\n",
       "    processing_level:           L4\n",
       "    cdm_data_type:              grid"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "fileObjs = generate_file_list(1, 367, 2016)\n",
    "print(f\"starting file: {fileObjs[0].split('/')[-1]}\")\n",
    "print(f\"ending file: {fileObjs[-1].split('/')[-1]}\")\n",
    "drop_vars = ['dt_1km_data', 'sst_anomaly']\n",
    "ds_netcdf = xr.open_mfdataset(fileObjs, parallel=True, combine='by_coords', mask_and_scale=False, drop_variables=drop_vars)\n",
    "ds_netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-17803.61192264279\n",
      "CPU times: user 973 ms, sys: 155 ms, total: 1.13 s\n",
      "Wall time: 38.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(-11290.59658304)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(ds_netcdf.where(ds_netcdf.analysed_sst != -32768).analysed_sst[356:366,:,:].sel(lat=slice(40,50),lon=slice(-170,-160)).mean().values)\n",
    "ds_netcdf.where(ds_netcdf.analysed_sst != -32768).analysed_sst.sel(time=time_slice).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-17803.61192264279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 32% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 481 ms, total: 11.3 s\n",
      "Wall time: 28.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(-11290.59658304)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(ds_zarr.where(ds_zarr.analysed_sst != -32768).analysed_sst[5318:5328,:,:].sel(lat=slice(40,50),lon=slice(-170,-160)).mean().values)\n",
    "ds_zarr.where(ds_zarr.analysed_sst != -32768).analysed_sst.sel(time=time_slice).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=True, client_kwargs=dict(region_name='us-east-1'))\n",
    "s3_store = s3fs.S3Map(root='nasa-eodc/eodc/mursst_zarr/5x1799x3600', s3=s3, check=False)\n",
    "ds_zarr = xr.open_zarr(s3_store, consolidated=True, mask_and_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(ds_zarr.where(ds_zarr.analysed_sst != -32768).analysed_sst[4577:4597,:,:].sel(lat=slice(40,50),lon=slice(-170,-160)).mean().values)\n",
    "ds_zarr.where(ds_zarr.analysed_sst != -32768).analysed_sst.sel(time=time_slice).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\r\n"
     ]
    }
   ],
   "source": [
    "!ls /s3fsx/eodc/mursst_netcdf/2017/**/*.nc | wc -l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:netcdf_to_zarr] *",
   "language": "python",
   "name": "conda-env-netcdf_to_zarr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
